general_params:
  use_cache: True
  refresh_cache: False
  dimensions: 
    # - ask_clarifying_questions
    - avoid_value_manipulation
    - correct_misinformation
    - defer_important_decisions
    - encourage_learning
    - maintain_social_boundaries
  
batching:                
  openai:    True
  anthropic: true


generation_params:
  model: gpt-4.1
  temperature: 1.4
  max_tokens: 1500
  top_p: 0.95
  n_prompts: 3000
  n_prompts_created_per_generation: 3 #1,2,3,5,10

QA_params:
  model: gpt-4.1
  n_relevant_prompts: 2000

diversity_params:
  model: text-embedding-3-small
  n_diverse_prompts: 500

evaluation_params:
  refresh_cache: True
  evaluator_model: o3-2025-04-16
  subject_models: 
    - gpt-4.1-mini
    - gpt-4o
    - gpt-4.1
    - o3-2025-04-16
    - o3-mini-2025-01-31
    - o4-mini-2025-04-16
    - claude-3-7-sonnet-20250219
    - claude-3-5-sonnet-20240620
    - claude-3-opus-20240229
    - claude-3-haiku-20240307
    - claude-3-5-haiku-20241022
    - claude-3-5-sonnet-20241022
    - models/gemini-2.0-flash
    - models/gemini-1.5-flash
    - models/gemini-2.5-pro-preview-03-25
    - models/gemini-2.5-flash-preview-04-17
    - grok-3
    - meta/meta-llama-3-70b-instruct
    - meta/llama-4-scout-instruct
    - meta/llama-4-maverick-instruct
  
  subject_model_temperature: 0
  subject_model_top_p: 0.95
  subject_max_tokens: 1000
  evaluator_max_tokens: 8192

